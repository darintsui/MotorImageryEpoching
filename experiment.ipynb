{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e33e73b-1a0d-4ca4-884c-1052556d1f15",
      "metadata": {
        "tags": [],
        "id": "1e33e73b-1a0d-4ca4-884c-1052556d1f15"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import mne\n",
        "from scipy.io import loadmat\n",
        "from tqdm import tqdm\n",
        "\n",
        "mne.set_log_level('ERROR')\n",
        "\n",
        "data_path = './BCICIV_2a_gdf'\n",
        "\n",
        "X_train_raws = []\n",
        "Y_train_raws = []\n",
        "X_test_raws = []\n",
        "Y_test_raws = []\n",
        "for file_id in range(1, 10):\n",
        "    for use_train in [True, False]:\n",
        "        # Read X\n",
        "        X_filename = os.path.join(data_path, f'A0{file_id}{[\"E\", \"T\"][use_train]}.gdf')\n",
        "        X_raw = mne.io.read_raw_gdf(X_filename)\n",
        "        X_raw.load_data()\n",
        "\n",
        "        # Read Y\n",
        "        Y_filename = os.path.join(data_path, f'A0{file_id}{[\"E\", \"T\"][use_train]}.mat')\n",
        "        Y_raw = loadmat(Y_filename)['classlabel'].T.squeeze()\n",
        "\n",
        "        if use_train:\n",
        "            X_train_raws.append(X_raw)\n",
        "            Y_train_raws.append(Y_raw)\n",
        "        else:\n",
        "            X_test_raws.append(X_raw)\n",
        "            Y_test_raws.append(Y_raw)\n",
        "\n",
        "# Reindex labels from 0 to 3\n",
        "Y_train_raw = np.hstack(Y_train_raws) - 1\n",
        "Y_test_raw = np.hstack(Y_test_raws) - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb3f603d-9bc6-474f-b562-638ed3aa840a",
      "metadata": {
        "tags": [],
        "id": "bb3f603d-9bc6-474f-b562-638ed3aa840a"
      },
      "outputs": [],
      "source": [
        "import pywt\n",
        "from sklearn import preprocessing\n",
        "\n",
        "def filter_epochs_comb(raws, tmin=1.0, tmax=4.0):\n",
        "    X = []\n",
        "    for raw in raws:\n",
        "        # Filter the raw signal with a band pass filter in 7-35 Hz\n",
        "        # 8 - 30\n",
        "        raw.filter(8., 30., fir_design='firwin')\n",
        "\n",
        "        # Remove the EOG channels and pick only desired EEG channels\n",
        "        raw.info['bads'] += ['EOG-left', 'EOG-central', 'EOG-right']\n",
        "        picks = mne.pick_types(raw.info, meg=False, eeg=True, eog=False, stim=False, exclude='bads')\n",
        "\n",
        "        # Find the events time positions\n",
        "        events, events_id = mne.events_from_annotations(raw)\n",
        "\n",
        "        # 1. left_hand = 769, 2. right_hand = 770, 3. foot = 771, 4. tongue = 772\n",
        "        events_key = ['769', '770', '771', '772'] if use_train else ['768']\n",
        "        use_events_id = {key: events_id[key] for key in events_key}\n",
        "\n",
        "        # Extracts epochs of from time peroid of between tmin and tmax from the datset into 288 events for all 4 classes\n",
        "        epochs = mne.Epochs(raw, events, use_events_id, tmin, tmax, proj=True, picks=picks, baseline=None, preload=True)\n",
        "        X.append(epochs.get_data())\n",
        "    X = np.vstack(X)\n",
        "\n",
        "    return X\n",
        "\n",
        "def feature_bands(X):\n",
        "    X_wpds = [[[None for j in range(X.shape[1])] for i in range(X.shape[0])] for b in range(1, 9)]\n",
        "    for i in range(X.shape[0]):\n",
        "        for j in range(X.shape[1]):\n",
        "            # signal is decomposed to level 5 with 'db4' wavelet\n",
        "            C = pywt.WaveletPacket(X[i, j, :], 'db4', mode='symmetric', maxlevel=5)\n",
        "            pos = [node.path for node in C.get_level(5, 'natural')]\n",
        "\n",
        "            for b in range(1, 9):\n",
        "                data = C[pos[b]].data\n",
        "                X_wpds[b - 1][i][j] = data\n",
        "    X_wpds = np.array(X_wpds)\n",
        "\n",
        "    return X_wpds\n",
        "\n",
        "def fit_CSP(X, Y, n_comps=4):\n",
        "    csps = []\n",
        "    for i in range(8):\n",
        "        csp = mne.decoding.CSP(n_components=n_comps, reg=None, log=True, norm_trace=False)\n",
        "        csp.fit(X[i, :, :, :], Y)\n",
        "        csps.append(csp)\n",
        "\n",
        "    return csps\n",
        "\n",
        "def mini_epochs(X_train, X_test, num_epochs=6, interval=None):\n",
        "    '''\n",
        "    (num_epochs - 1) * increment + interval = 3s\n",
        "\n",
        "    original: num_epochs=1\n",
        "    fixed-window: num_epochs=n\n",
        "    sliding-window: num_epochs=n, interval=t\n",
        "    '''\n",
        "\n",
        "    if interval is None:\n",
        "        interval = 3 / num_epochs\n",
        "        increment = interval\n",
        "    else:\n",
        "        increment = (3 - interval) / (num_epochs - 1)\n",
        "\n",
        "    X_train_epochs = []\n",
        "    X_test_epochs = []\n",
        "    for tmin in tqdm(np.arange(1, 4 - interval + increment, increment)):\n",
        "        X_train_filter = filter_epochs_comb(X_train, tmin=tmin, tmax=tmin + interval)\n",
        "        X_test_filter = filter_epochs_comb(X_test, tmin=tmin, tmax=tmin + interval)\n",
        "\n",
        "        X_train_wpd = feature_bands(X_train_filter)\n",
        "        X_test_wpd = feature_bands(X_test_filter)\n",
        "\n",
        "        csps = fit_CSP(X_train_wpd, Y_train_raw, n_comps=16)\n",
        "        X_train_csp = np.concatenate([csps[i].transform(X_train_wpd[i, :, :, :]) for i in range(8)], axis=-1)\n",
        "        X_test_csp = np.concatenate([csps[i].transform(X_test_wpd[i, :, :, :]) for i in range(8)], axis=-1)\n",
        "\n",
        "        X_train_epochs.append(X_train_csp)\n",
        "        X_test_epochs.append(X_test_csp)\n",
        "\n",
        "    num_feats = list(map(lambda x: x.shape[1], X_train_epochs))\n",
        "    X_train_epochs = np.hstack(X_train_epochs)\n",
        "    X_test_epochs = np.hstack(X_test_epochs)\n",
        "\n",
        "    return X_train_epochs, X_test_epochs, num_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bfb57e-2337-416d-be31-39959522c0d8",
      "metadata": {
        "tags": [],
        "id": "48bfb57e-2337-416d-be31-39959522c0d8"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "class MiniEpochEnsemble(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, num_feats, learner='xgb'):\n",
        "        self.num_feats = num_feats\n",
        "        self.learner = learner\n",
        "\n",
        "        ends = np.cumsum(num_feats)\n",
        "        self.input_ranges = [(0, ends[i]) if i == 0 else (ends[i - 1], ends[i]) for i in range(len(ends))]\n",
        "        self.base_learners = [self._learner_get() for i in range(len(num_feats))]\n",
        "        self.ense_learner = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = check_X_y(X, y)\n",
        "        self.classes_ = unique_labels(y)\n",
        "        self.X_ = X\n",
        "        self.y_ = y\n",
        "\n",
        "        margins = []\n",
        "        for input_range, base_learner in tqdm(zip(self.input_ranges, self.base_learners)):\n",
        "            X_mini = X[:, input_range[0]:input_range[1]]\n",
        "            self._learner_fit(X_mini, Y_train, base_learner)\n",
        "            margins.append(self._learner_margin(X_mini, base_learner))\n",
        "        margins = np.array(margins)\n",
        "\n",
        "        self.ense_learner = LogisticRegression(max_iter=1000, random_state=0)\n",
        "        self.ense_learner.fit(np.hstack(margins), Y_train)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        check_is_fitted(self)\n",
        "        X = check_array(X)\n",
        "\n",
        "        margins = []\n",
        "        for input_range, base_learner in tqdm(zip(self.input_ranges, self.base_learners)):\n",
        "            X_mini = X[:, input_range[0]:input_range[1]]\n",
        "            margins.append(self._learner_margin(X_mini, base_learner))\n",
        "        margins = np.array(margins)\n",
        "\n",
        "        Y = self.ense_learner.predict(np.hstack(margins))\n",
        "\n",
        "        return Y\n",
        "\n",
        "    def _learner_get(self):\n",
        "        if self.learner == 'svm':\n",
        "            clf = SVC()\n",
        "        elif self.learner == 'xgb':\n",
        "            clf = XGBClassifier(learning_rate=3e-1, max_depth=4, reg_lambda=1e2)\n",
        "        elif self.learner == 'fcn':\n",
        "            clf = MLPClassifier(alpha=1e-2, hidden_layer_sizes=(50, 50, 50), random_state=1)\n",
        "        else:\n",
        "            raise ValueError(f'Base learner {self.learner} not supported!')\n",
        "\n",
        "        return clf\n",
        "\n",
        "    def _learner_fit(self, X, Y, clf):\n",
        "        if self.learner == 'svm':\n",
        "            clf.fit(X, Y)\n",
        "        elif self.learner == 'xgb':\n",
        "            clf.fit(X, Y)\n",
        "        elif self.learner == 'fcn':\n",
        "            clf.fit(X, Y)\n",
        "        else:\n",
        "            raise ValueError(f'Base learner {self.learner} not supported!')\n",
        "\n",
        "        return clf\n",
        "\n",
        "    def _learner_margin(self, X, clf):\n",
        "        if self.learner == 'svm':\n",
        "            scores = clf.decision_function(X)\n",
        "        elif self.learner == 'xgb':\n",
        "            scores = clf.predict(X, output_margin=True)\n",
        "        elif self.learner == 'fcn':\n",
        "            scores = clf.predict_proba(X)\n",
        "        else:\n",
        "            raise ValueError(f'Base learner {self.learner} not supported!')\n",
        "\n",
        "        return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe242e3-1124-424f-9363-a299bb68bbbd",
      "metadata": {
        "id": "6fe242e3-1124-424f-9363-a299bb68bbbd"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "def split_dataset(X_train_raw, Y_train_raw, X_test_raw, Y_test_raw, test_size=0.2):\n",
        "    # X = np.vstack((X_train_raw, X_test_raw))\n",
        "    # Y = np.hstack((Y_train_raw, Y_test_raw))\n",
        "    # X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "    # X_train = normalize(X_train)\n",
        "    # X_test = normalize(X_test)\n",
        "\n",
        "    X_train = normalize(X_train_raw)\n",
        "    X_test = normalize(X_test_raw)\n",
        "    Y_train = Y_train_raw\n",
        "    Y_test = Y_test_raw\n",
        "\n",
        "    return X_train, Y_train, X_test, Y_test\n",
        "\n",
        "def eval_clf(X_train, Y_train, X_test, Y_test, clf):\n",
        "    clf.fit(X_train, Y_train)\n",
        "    train_accu = clf.score(X_train, Y_train)\n",
        "    test_accu = clf.score(X_test, Y_test)\n",
        "\n",
        "    return train_accu, test_accu"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efd957c4-f9b5-48fe-8900-9149df5aac36",
      "metadata": {
        "id": "efd957c4-f9b5-48fe-8900-9149df5aac36"
      },
      "source": [
        "## Original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0ee2a25-77c1-46d7-9558-2983250c389e",
      "metadata": {
        "id": "d0ee2a25-77c1-46d7-9558-2983250c389e",
        "outputId": "61e86cc3-ece3-4615-9823-e4ccec81e800"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:52<00:00, 52.42s/it]\n",
            "/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "X_train_orig, X_test_orig, num_feats_fwin = mini_epochs(X_train_raws, X_test_raws, num_epochs=1)\n",
        "X_train, Y_train, X_test, Y_test = split_dataset(X_train_orig, Y_train_raw, X_test_orig, Y_test_raw)\n",
        "\n",
        "mlp = MLPClassifier(alpha=1e-2, hidden_layer_sizes=(50, 50, 50), random_state=1)\n",
        "mlp_scores = eval_clf(X_train, Y_train, X_test, Y_test, mlp)\n",
        "\n",
        "svm = SVC(C=1)\n",
        "svm_scores = eval_clf(X_train, Y_train, X_test, Y_test, svm)\n",
        "\n",
        "xgb = XGBClassifier(learning_rate=3e-1, max_depth=4, reg_lambda=1e2)\n",
        "xgb_scores = eval_clf(X_train, Y_train, X_test, Y_test, xgb)\n",
        "\n",
        "orig_scores = [mlp_scores, svm_scores, xgb_scores]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c64b6b0-e4f9-4429-a5e5-914ebd7ab5aa",
      "metadata": {
        "tags": [],
        "id": "3c64b6b0-e4f9-4429-a5e5-914ebd7ab5aa"
      },
      "outputs": [],
      "source": [
        "with open('orig_scores.npy', 'wb') as file:\n",
        "    np.save(file, orig_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1ddb1d1-a4dc-4da6-8c69-dba1e272cfb5",
      "metadata": {
        "id": "a1ddb1d1-a4dc-4da6-8c69-dba1e272cfb5"
      },
      "source": [
        "## Fixed window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50507cf2-4cca-4291-9930-d29ab171ca03",
      "metadata": {
        "id": "50507cf2-4cca-4291-9930-d29ab171ca03",
        "outputId": "12e0e128-9106-4612-e5c2-4849d845d421"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [02:32<00:00, 50.83s/it]\n",
            "0it [00:00, ?it/s]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "1it [00:05,  5.66s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "2it [00:11,  5.61s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "3it [00:16,  5.58s/it]\n",
            "3it [00:00, 243.64it/s]\n",
            "3it [00:00, 253.51it/s]\n",
            "3it [00:02,  1.25it/s]\n",
            "3it [00:01,  2.51it/s]\n",
            "3it [00:01,  2.51it/s]\n",
            "3it [05:48, 116.18s/it]\n",
            "3it [00:00, 107.78it/s]\n",
            "3it [00:00, 103.33it/s]\n",
            "100%|██████████| 6/6 [05:05<00:00, 50.91s/it]\n",
            "0it [00:00, ?it/s]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "1it [00:06,  6.28s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "2it [00:12,  5.98s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "3it [00:18,  6.02s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "4it [00:24,  5.98s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "5it [00:29,  5.95s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "6it [00:35,  5.96s/it]\n",
            "6it [00:00, 262.18it/s]\n",
            "6it [00:00, 266.78it/s]\n",
            "6it [00:04,  1.24it/s]\n",
            "6it [00:02,  2.48it/s]\n",
            "6it [00:02,  2.44it/s]\n",
            "6it [11:37, 116.21s/it]\n",
            "6it [00:00, 104.59it/s]\n",
            "6it [00:00, 102.52it/s]\n",
            "100%|██████████| 12/12 [09:59<00:00, 49.98s/it]\n",
            "0it [00:00, ?it/s]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "1it [00:05,  5.62s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "2it [00:11,  5.56s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "3it [00:16,  5.49s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "4it [00:21,  5.46s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "5it [00:27,  5.44s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "6it [00:32,  5.42s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "7it [00:38,  5.42s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "8it [00:43,  5.46s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "9it [00:49,  5.47s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "10it [00:54,  5.47s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "11it [01:00,  5.46s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "12it [01:05,  5.47s/it]\n",
            "12it [00:00, 259.61it/s]\n",
            "12it [00:00, 268.20it/s]\n",
            "12it [00:10,  1.19it/s]\n",
            "12it [00:05,  2.27it/s]\n",
            "12it [00:05,  2.32it/s]\n",
            "12it [23:15, 116.28s/it]\n",
            "12it [00:00, 75.00it/s]\n",
            "12it [00:00, 75.99it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[(1.0, 0.4363425925925926),\n",
              "  (0.9000771604938271, 0.4957561728395062),\n",
              "  (1.0, 0.48842592592592593),\n",
              "  (1.0, 0.3753858024691358),\n",
              "  (0.910108024691358, 0.42978395061728397),\n",
              "  (1.0, 0.4471450617283951)],\n",
              " [(1.0, 0.44328703703703703),\n",
              "  (0.9618055555555556, 0.5142746913580247),\n",
              "  (1.0, 0.4903549382716049),\n",
              "  (0.9996141975308642, 0.3765432098765432),\n",
              "  (0.9741512345679012, 0.4166666666666667),\n",
              "  (1.0, 0.4818672839506173)],\n",
              " [(1.0, 0.4756944444444444),\n",
              "  (0.9884259259259259, 0.5300925925925926),\n",
              "  (1.0, 0.5061728395061729),\n",
              "  (0.9984567901234568, 0.4174382716049383),\n",
              "  (1.0, 0.4077932098765432),\n",
              "  (1.0, 0.48302469135802467)]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fwin_scores = []\n",
        "for num_epochs in [3, 6, 12]:\n",
        "    X_train_fwin, X_test_fwin, num_feats_fwin = mini_epochs(X_train_raws, X_test_raws, num_epochs=num_epochs)\n",
        "    X_train, Y_train, X_test, Y_test = split_dataset(X_train_fwin, Y_train_raw, X_test_fwin, Y_test_raw)\n",
        "\n",
        "    mlp = MLPClassifier(alpha=1e-2, hidden_layer_sizes=(50, 50, 50), random_state=1)\n",
        "    mlp_scores = eval_clf(X_train, Y_train, X_test, Y_test, mlp)\n",
        "\n",
        "    svm = SVC(C=1)\n",
        "    svm_scores = eval_clf(X_train, Y_train, X_test, Y_test, svm)\n",
        "\n",
        "    xgb = XGBClassifier(learning_rate=3e-1, max_depth=4, reg_lambda=1e2)\n",
        "    xgb_scores = eval_clf(X_train, Y_train, X_test, Y_test, xgb)\n",
        "\n",
        "    mlp_ense = MiniEpochEnsemble(num_feats_fwin, 'fcn')\n",
        "    mlp_ense_scores = eval_clf(X_train, Y_train, X_test, Y_test, mlp_ense)\n",
        "\n",
        "    svm_ense = MiniEpochEnsemble(num_feats_fwin, 'svm')\n",
        "    svm_ense_scores = eval_clf(X_train, Y_train, X_test, Y_test, svm_ense)\n",
        "\n",
        "    xgb_ense = MiniEpochEnsemble(num_feats_fwin, 'xgb')\n",
        "    xgb_ense_scores = eval_clf(X_train, Y_train, X_test, Y_test, xgb_ense)\n",
        "\n",
        "    fwin_scores.append([mlp_scores, svm_scores, xgb_scores, mlp_ense_scores, svm_ense_scores, xgb_ense_scores])\n",
        "fwin_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4905e29d-f7bb-4cda-b08e-c45abb772006",
      "metadata": {
        "tags": [],
        "id": "4905e29d-f7bb-4cda-b08e-c45abb772006"
      },
      "outputs": [],
      "source": [
        "with open('fwin_scores.npy', 'wb') as file:\n",
        "    np.save(file, fwin_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c74f8e3-9b14-496a-a0bd-2c7141e7f450",
      "metadata": {
        "id": "6c74f8e3-9b14-496a-a0bd-2c7141e7f450"
      },
      "source": [
        "## Sliding window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87f16b40-a78a-4054-8697-1e61b5a74e09",
      "metadata": {
        "tags": [],
        "id": "87f16b40-a78a-4054-8697-1e61b5a74e09",
        "outputId": "e0112fd8-ec7e-4b3c-b404-3d0498fada2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6/6 [05:01<00:00, 50.28s/it]\n",
            "0it [00:00, ?it/s]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "1it [00:05,  5.83s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "2it [00:11,  5.59s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "3it [00:16,  5.55s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "4it [00:22,  5.53s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "5it [00:27,  5.50s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "6it [00:33,  5.52s/it]\n",
            "6it [00:00, 252.21it/s]\n",
            "6it [00:00, 262.38it/s]\n",
            "6it [00:04,  1.24it/s]\n",
            "6it [00:02,  2.49it/s]\n",
            "6it [00:02,  2.47it/s]\n",
            "6it [11:37, 116.23s/it]\n",
            "6it [00:00, 113.88it/s]\n",
            "6it [00:00, 100.46it/s]\n",
            "100%|██████████| 6/6 [05:05<00:00, 50.86s/it]\n",
            "0it [00:00, ?it/s]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "1it [00:06,  6.09s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "2it [00:12,  6.24s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "3it [00:19,  6.46s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "4it [00:25,  6.42s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "5it [00:32,  6.51s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "6it [00:38,  6.43s/it]\n",
            "6it [00:00, 264.78it/s]\n",
            "6it [00:00, 252.91it/s]\n",
            "6it [00:04,  1.22it/s]\n",
            "6it [00:02,  2.34it/s]\n",
            "6it [00:02,  2.33it/s]\n",
            "6it [11:35, 115.90s/it]\n",
            "6it [00:00, 116.63it/s]\n",
            "6it [00:00, 101.58it/s]\n",
            "100%|██████████| 7/7 [05:53<00:00, 50.56s/it]\n",
            "0it [00:00, ?it/s]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "1it [00:05,  5.54s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "2it [00:11,  5.60s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "3it [00:16,  5.56s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "4it [00:22,  5.64s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "5it [00:28,  5.71s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "6it [00:34,  5.73s/it]/home/l1qiao/Projects/venv3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "7it [00:39,  5.69s/it]\n",
            "7it [00:00, 268.42it/s]\n",
            "7it [00:00, 265.47it/s]\n",
            "7it [00:05,  1.26it/s]\n",
            "7it [00:02,  2.47it/s]\n",
            "7it [00:02,  2.46it/s]\n",
            "7it [13:33, 116.22s/it]\n",
            "7it [00:00, 62.49it/s]\n",
            "7it [00:00, 61.15it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[(1.0, 0.44367283950617287),\n",
              "  (0.9444444444444444, 0.5169753086419753),\n",
              "  (1.0, 0.5227623456790124),\n",
              "  (0.9949845679012346, 0.4378858024691358),\n",
              "  (0.9598765432098766, 0.44328703703703703),\n",
              "  (1.0, 0.5084876543209876)],\n",
              " [(1.0, 0.4737654320987654),\n",
              "  (0.9293981481481481, 0.5254629629629629),\n",
              "  (1.0, 0.5162037037037037),\n",
              "  (0.996141975308642, 0.42592592592592593),\n",
              "  (0.9444444444444444, 0.435570987654321),\n",
              "  (1.0, 0.498070987654321)],\n",
              " [(1.0, 0.4984567901234568),\n",
              "  (0.9286265432098766, 0.560570987654321),\n",
              "  (1.0, 0.5582561728395061),\n",
              "  (0.9845679012345679, 0.5),\n",
              "  (0.9436728395061729, 0.4699074074074074),\n",
              "  (1.0, 0.5536265432098766)]]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "swin_scores = []\n",
        "for interval in [0.75, 1, 1.25]:\n",
        "    X_train_swin, X_test_swin, num_feats_swin = mini_epochs(X_train_raws, X_test_raws, num_epochs=6, interval=interval)\n",
        "    X_train, Y_train, X_test, Y_test = split_dataset(X_train_swin, Y_train_raw, X_test_swin, Y_test_raw)\n",
        "\n",
        "    mlp = MLPClassifier(alpha=1e-2, hidden_layer_sizes=(50, 50, 50), random_state=1)\n",
        "    mlp_scores = eval_clf(X_train, Y_train, X_test, Y_test, mlp)\n",
        "\n",
        "    svm = SVC(C=1)\n",
        "    svm_scores = eval_clf(X_train, Y_train, X_test, Y_test, svm)\n",
        "\n",
        "    xgb = XGBClassifier(learning_rate=3e-1, max_depth=4, reg_lambda=1e2)\n",
        "    xgb_scores = eval_clf(X_train, Y_train, X_test, Y_test, xgb)\n",
        "\n",
        "    mlp_ense = MiniEpochEnsemble(num_feats_swin, 'fcn')\n",
        "    mlp_ense_scores = eval_clf(X_train, Y_train, X_test, Y_test, mlp_ense)\n",
        "\n",
        "    svm_ense = MiniEpochEnsemble(num_feats_swin, 'svm')\n",
        "    svm_ense_scores = eval_clf(X_train, Y_train, X_test, Y_test, svm_ense)\n",
        "\n",
        "    xgb_ense = MiniEpochEnsemble(num_feats_swin, 'xgb')\n",
        "    xgb_ense_scores = eval_clf(X_train, Y_train, X_test, Y_test, xgb_ense)\n",
        "\n",
        "    swin_scores.append([mlp_scores, svm_scores, xgb_scores, mlp_ense_scores, svm_ense_scores, xgb_ense_scores])\n",
        "swin_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da2096e2-ab63-4b0d-96ca-d5a9360107d2",
      "metadata": {
        "tags": [],
        "id": "da2096e2-ab63-4b0d-96ca-d5a9360107d2"
      },
      "outputs": [],
      "source": [
        "with open('swin_scores.npy', 'wb') as file:\n",
        "    np.save(file, swin_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a651152-c834-4350-a5dc-871b006bc0ca",
      "metadata": {
        "id": "3a651152-c834-4350-a5dc-871b006bc0ca"
      },
      "source": [
        "## Table 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9d9092-b44b-4c0a-b018-30b7f822fe43",
      "metadata": {
        "tags": [],
        "id": "7c9d9092-b44b-4c0a-b018-30b7f822fe43",
        "outputId": "b67a7376-7d35-4102-9075-c8d30291521c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLP</th>\n",
              "      <th>SVM</th>\n",
              "      <th>XGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Original</th>\n",
              "      <td>37.35%</td>\n",
              "      <td>40.47%</td>\n",
              "      <td>38.12%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fixed N=3</th>\n",
              "      <td>43.63%</td>\n",
              "      <td>49.58%</td>\n",
              "      <td>48.84%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fixed N=6</th>\n",
              "      <td>44.33%</td>\n",
              "      <td>51.43%</td>\n",
              "      <td>49.04%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fixed N=12</th>\n",
              "      <td>47.57%</td>\n",
              "      <td>53.01%</td>\n",
              "      <td>50.62%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sliding T=0.75s</th>\n",
              "      <td>44.37%</td>\n",
              "      <td>51.70%</td>\n",
              "      <td>52.28%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sliding T=1.00s</th>\n",
              "      <td>47.38%</td>\n",
              "      <td>52.55%</td>\n",
              "      <td>51.62%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sliding T=1.25s</th>\n",
              "      <td>49.85%</td>\n",
              "      <td>56.06%</td>\n",
              "      <td>55.83%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    MLP     SVM     XGB\n",
              "Original         37.35%  40.47%  38.12%\n",
              "Fixed N=3        43.63%  49.58%  48.84%\n",
              "Fixed N=6        44.33%  51.43%  49.04%\n",
              "Fixed N=12       47.57%  53.01%  50.62%\n",
              "Sliding T=0.75s  44.37%  51.70%  52.28%\n",
              "Sliding T=1.00s  47.38%  52.55%  51.62%\n",
              "Sliding T=1.25s  49.85%  56.06%  55.83%"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "table1 = []\n",
        "\n",
        "orig_row = []\n",
        "for orig_score in orig_scores:\n",
        "    orig_row.append(orig_score[1])\n",
        "table1.append(orig_row)\n",
        "\n",
        "for fwin_score in fwin_scores:\n",
        "    fwin_row = []\n",
        "    for i in range(3):\n",
        "        fwin_row.append(fwin_score[i][1])\n",
        "    table1.append(fwin_row)\n",
        "\n",
        "for swin_score in swin_scores:\n",
        "    swin_row = []\n",
        "    for i in range(3):\n",
        "        swin_row.append(swin_score[i][1])\n",
        "    table1.append(swin_row)\n",
        "\n",
        "columns = ['MLP', 'SVM', 'XGB']\n",
        "index=['Original', 'Fixed N=3', 'Fixed N=6', 'Fixed N=12', 'Sliding T=0.75s', 'Sliding T=1.00s', 'Sliding T=1.25s']\n",
        "pd.DataFrame(np.array(table1) * 100, columns=columns, index=index).applymap(\"{0:.2f}%\".format)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c392ee4-80de-4761-abc4-c40dd488254c",
      "metadata": {
        "id": "1c392ee4-80de-4761-abc4-c40dd488254c"
      },
      "source": [
        "## Table 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06900c46-e139-47bb-8b26-8cde32f4cdd6",
      "metadata": {
        "tags": [],
        "id": "06900c46-e139-47bb-8b26-8cde32f4cdd6",
        "outputId": "2f5850ed-4221-42a7-c0fa-bbd00e4dbd92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MLP</th>\n",
              "      <th>SVM</th>\n",
              "      <th>XGB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Fixed N=3</th>\n",
              "      <td>37.54%</td>\n",
              "      <td>42.98%</td>\n",
              "      <td>44.71%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fixed N=6</th>\n",
              "      <td>37.65%</td>\n",
              "      <td>41.67%</td>\n",
              "      <td>48.19%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fixed N=12</th>\n",
              "      <td>41.74%</td>\n",
              "      <td>40.78%</td>\n",
              "      <td>48.30%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sliding T=0.75s</th>\n",
              "      <td>43.79%</td>\n",
              "      <td>44.33%</td>\n",
              "      <td>50.85%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sliding T=1.00s</th>\n",
              "      <td>42.59%</td>\n",
              "      <td>43.56%</td>\n",
              "      <td>49.81%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sliding T=1.25s</th>\n",
              "      <td>50.00%</td>\n",
              "      <td>46.99%</td>\n",
              "      <td>55.36%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    MLP     SVM     XGB\n",
              "Fixed N=3        37.54%  42.98%  44.71%\n",
              "Fixed N=6        37.65%  41.67%  48.19%\n",
              "Fixed N=12       41.74%  40.78%  48.30%\n",
              "Sliding T=0.75s  43.79%  44.33%  50.85%\n",
              "Sliding T=1.00s  42.59%  43.56%  49.81%\n",
              "Sliding T=1.25s  50.00%  46.99%  55.36%"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "table2 = []\n",
        "\n",
        "for fwin_score in fwin_scores:\n",
        "    fwin_row = []\n",
        "    for i in range(3, 6):\n",
        "        fwin_row.append(fwin_score[i][1])\n",
        "    table2.append(fwin_row)\n",
        "\n",
        "for swin_score in swin_scores:\n",
        "    swin_row = []\n",
        "    for i in range(3, 6):\n",
        "        swin_row.append(swin_score[i][1])\n",
        "    table2.append(swin_row)\n",
        "\n",
        "columns = ['MLP', 'SVM', 'XGB']\n",
        "index=['Fixed N=3', 'Fixed N=6', 'Fixed N=12', 'Sliding T=0.75s', 'Sliding T=1.00s', 'Sliding T=1.25s']\n",
        "pd.DataFrame(np.array(table2) * 100, columns=columns, index=index).applymap(\"{0:.2f}%\".format)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}